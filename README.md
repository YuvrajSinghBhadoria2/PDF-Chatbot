# Chat with Multiple PDFs (RAG)

A Streamlit app that lets you upload multiple PDFs, builds a local FAISS vector index with `sentence-transformers/all-MiniLM-L6-v2`, and answers questions using Groq's `llama-3.1-8b-instant` via LangChain.

## Features

- Upload multiple PDF files and extract text
- Chunk text and embed with HuggingFace embeddings
- Persist a local FAISS index in `faiss_index/`
- Ask questions grounded in your PDFs; responses from Groq LLM
- Download conversation history as CSV from the sidebar

## Quick Start

### Prerequisites

- Python 3.9+ recommended
- A Groq API key for LLM inference

### Setup

```bash
# (optional) create and activate a virtual environment
python -m venv .venv
source .venv/bin/activate  # on macOS/Linux
# .venv\Scripts\activate   # on Windows

# install dependencies
pip install -r requirements.txt

# additional packages used by the app but not listed explicitly
pip install langchain-groq python-dotenv
```

Create a `.env` file in the project root:

```bash
GROQ_API_KEY=your_api_key_here
```

### Run

```bash
streamlit run app.py
```

Open the local URL Streamlit prints (usually `http://localhost:8501`).

## Usage

- Use the file uploader to add one or more PDFs
- Enter your question in the text input
- The app builds or loads a FAISS index at `faiss_index/` and retrieves the top 4 relevant chunks
- The response is generated by Groq's `llama-3.1-8b-instant`
- Use `Reset` to clear conversation, `Rerun` to reload the app
- Download the conversation as CSV from the sidebar

## Configuration

- Chunking: adjust `chunk_size` and `chunk_overlap` in `app.py:47`
- LLM model: change `model` in `app.py:61`
- Retrieval `k`: adjust the number of results in `app.py:110`
- FAISS persistence path: update `persist_path` in `app.py:90`

## Project Structure

- `app.py` — Streamlit app entrypoint (`app.py:212` calls `main()`)
- `requirements.txt` — Python dependencies
- `faiss_index/` — created automatically to store the vector index
- `.env` — environment variables (create locally; do not commit)

## Troubleshooting

- Missing packages: ensure `langchain-groq` and `python-dotenv` are installed
- API errors: verify `GROQ_API_KEY` is present in `.env` or your environment
- Index issues: delete `faiss_index/` and rerun to rebuild the index
- PDF parsing: if a file fails to load, try re-exporting the PDF or simplifying its content

## Notes

- The app uses `allow_dangerous_deserialization=True` when loading FAISS to support local index persistence
- On first run with new PDFs, building the index may take time depending on file sizes
